{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Tutorial** : What cartographic representation for a point data set ? \n",
    "## Overview of some existing techniques with the CartAGen tool\n",
    "Press **`space bar`** to display the next slide.\n",
    "_If this Notebook doesn't appear in slideshow mode, reload the page_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- üôã **For whom ?** : \n",
    "  - people who have spatial data to be enhanced by maps, but don't know which cartographic representation to choose.\n",
    "  - expert cartographers wishing to discover the **possibilities of cartographic generalization** offered by the CartAGen tool\n",
    "  - anyone wishing to find out about the various problems encountered when creating maps from point data (and how to get around these problems).\n",
    "\n",
    "Press **`spacebar`** and **`scroll down`** to display the following message. _Reload the page if you can't scroll down._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- ‚ùì **What is CartAGen ?** :\n",
    "    - an **open source Python library** made by **IGN** (i.e the french national mapping agency) researchers\n",
    "    - a tool to carry out cartographic generalization processes and **automate** them\n",
    "    - a **QGIS plugin** to use the Python library in a GIS environment  \n",
    "    \n",
    "Press **`space bar`** and **`scroll down`** to show next message "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- üìó **How to use this Notebook ?** : \n",
    "    - a Notebook is a document that mixes **markdown cells** (i.e. cells with formatted text like this one) and **code cells**, which you can modify and execute at will\n",
    "    - it comes with a **sample data set** on which you can **test** the various features of the CartAGen python library\n",
    "    - you can import your **own data** and run the code cells of this Notebook, or use the CartAGen tool in **another environment** (QGIS or python script)\n",
    "\n",
    "Press **`right arrow`** to show next slide and start part 0, or press **`space bar`** to show sub-slide and see useful links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "   \n",
    "- üîó **Useful links** : \n",
    "    - [Library repository](https://github.com/LostInZoom/cartagen4py?tab=readme-ov-file) \n",
    "    - [QGIS Plugin repository](https://github.com/LostInZoom/cartagen-qgis)\n",
    "    - [CartAGen documentation](https://cartagen.readthedocs.io/en/latest/)\n",
    "\n",
    "_by Paul Bourcier, 2024 - EUPL 1.2_\n",
    "\n",
    "Press **`space bar`** to show next slide, press **`shift + space bar`** to go backward\\\n",
    "**`Click`** question mark icon to show other shortcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ‚öôÔ∏è **Part 0 :** Preparing the working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Press **`space bar`** to show code cell, then press **`shift + enter`** to execute it\\\n",
    "**`*`** symbol means code output is loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import cartagen as cg # the main library, containing cartographic generalization algorithms\n",
    "\n",
    "#geographic data manipulation \n",
    "import geopandas as gp # used to import and manipulate geographic data\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point # Create and manipulate geometries\n",
    "from shapely.ops import linemerge, transform\n",
    "from time import sleep # Creating loading bar\n",
    "\n",
    "#displaying the data\n",
    "from matplotlib import pyplot as plt # for ploting results, especially maps\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar # adding scalebar to the maps\n",
    "import matplotlib.colors as matcol # generating color palettes\n",
    "from matplotlib.path import Path  # Plot generation\n",
    "from matplotlib.patches import PathPatch # Plot generation\n",
    "from mpl_toolkits.axisartist.axislines import Subplot # Plot generation\n",
    "import matplotlib.colors as mcolors #generating colors \n",
    "import matplotlib.cm as cm #used to display colorbar\n",
    "import contextily as ctx # Adding basemaps\n",
    "\n",
    "#creating interactive outputs\n",
    "import ipywidgets # creation of interactive plots\n",
    "import pydeck as pdk #deck.gl in Python for interactive maps\n",
    "import json #manipulating dictionnaries\n",
    "import progressbar\n",
    "import ipyleaflet #creates interactive maps\n",
    "\n",
    "# other data manipulation\n",
    "import pandas as pd # used to concatenate datas\n",
    "import numpy as np # Using mathematical operations in Python\n",
    "from sklearn import cluster #clustering methods\n",
    "\n",
    "import random #generating random numbers\n",
    "import warnings # Remove warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*GeoDataFrame you are attempting to plot is empty.*\") # Remove user warning \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*CRS not set for some of the concatenation inputs.*.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ‚ùå **Part 1 :** Common issues with point data representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nowadays, more and more spatial data shared by data producers takes the form of point data, i.e. data associated with a pair of x/y coordinates, enabling it to be integrated into maps. These point data concern a wide variety of themes: environment, population, urban planning, mobility, etc. \n",
    "\n",
    "Let's take a look at the challenges involved in mapping this type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideOutput": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **1.1/** Why displaying a raw dataset can lead to limitations?\n",
    "\n",
    "When creating maps with the aim of showing the spatial distribution of a phenomenon, displaying each point in our dataset can prove problematic. Let's take the example of restaurants selling crepes in Brittany, France:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**1.1.1/** Displaying maps of creperies in Brittany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "üí¨ This Notebook is meant to be interactive (beyond code modifications) : after **running** a code cell, you will often be able to **change** algorithm parameters or figure settings, thanks to **buttons**. Let's try changing the figure size thanks to a slider button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Displaying maps of crepe restaurants in Brittany\n",
    "brittany = gp.read_file('data/puntos/brittany.geojson')\n",
    "crepes = gp.read_file('data/puntos/crepes.geojson')\n",
    "widgets = [\n",
    "    '', progressbar.Percentage(), ' ',  \n",
    "    progressbar.Bar(marker='üü©', left='', right='                                                  ', width = 1) \n",
    "]\n",
    "\n",
    "def plt_bre_1(figure_size):\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=2,widgets=widgets) as bar:\n",
    "        ax = brittany.plot(facecolor = 'None', edgecolor = \"grey\", linewidth = 0.5, figsize = (figure_size,figure_size))\n",
    "        bar.update(1)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        scalebar = AnchoredSizeBar(ax.transData,\n",
    "                                10000,  \n",
    "                                '10 km',  \n",
    "                                'lower left',  \n",
    "                                pad=0.5,\n",
    "                                color='black',\n",
    "                                frameon=True,\n",
    "                                size_vertical=1)\n",
    "        ax.add_artist(scalebar)\n",
    "\n",
    "        crepes.plot(ax=ax)    \n",
    "        bar.update(2)\n",
    "    \n",
    "ipywidgets.interact(plt_bre_1, figure_size = ipywidgets.IntSlider(value =12, min = 1, max = 16,step = 1,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "üí¨ This map shows all the creperies in Brittany that are represented in the [OSM](https://www.openstreetmap.org/#map=14/48.81620/-1.17910) database. As some points overlap, it is difficult to read the spatial distribution of these restaurants. Although we understand that there are more restaurants in the main cities and on certain parts of the coast, we can't really say whether there are more restaurants in Rennes or Brest, for example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "üí¨ Let's try to lower the opacity of the points, so we can see more easily when several points are overlaping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**1.1.2/** Displaying creperies with opacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Trying to lower the opacity to see if spatial distribution are more readable\n",
    "\n",
    "def plt_bre_1(figure_size, opacity):\n",
    "    with progressbar.ProgressBar(max_value=2,widgets=widgets) as bar:\n",
    "        ax = brittany.plot(facecolor = 'None', edgecolor = \"grey\", linewidth = 0.5, figsize = (figure_size,figure_size))\n",
    "        bar.update(1)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "        scalebar = AnchoredSizeBar(ax.transData,\n",
    "                                10000,  \n",
    "                                '10 km',  \n",
    "                                'lower left',  \n",
    "                                pad=0.5,\n",
    "                                color='black',\n",
    "                                frameon=True,\n",
    "                                size_vertical=1)\n",
    "        ax.add_artist(scalebar)\n",
    "\n",
    "        crepes.plot(ax=ax, alpha = opacity)\n",
    "        bar.update(2)\n",
    "ipywidgets.interact(plt_bre_1, figure_size = ipywidgets.IntSlider(value =12, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                               opacity = ipywidgets.FloatSlider(value =0.7, min = 0, max = 1,step = 0.01,continuous_update=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thanks to this technique, the spatial distribution becomes clearer. But it's still not enough to determine in which city there are the most creperies! We'll look at some techniques for improving map legibility with regard to the spatial distribution of these restaurants in part 2... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **1.2/** Point data sets in multi-scale maps : the persistant problem of scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nowadays, geographical data is often enhanced through interactive maps, i.e. maps on which the user can modify the view by moving it, or zooming. As far as point data is concerned, it's true that this medium offers the possibility of seeing precisely where points are located in a given area. However, the display of raw data still generates problems of map legibility at certain scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's take the example of parking meters in Paris :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**1.2.1/** Interactive map of parking meters in Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "üí¨ Once the interactive map is loaded, you can navigate through it just like in other website !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "horo = gp.read_file('data/puntos/horodateurs-mobiliers.geojson')\n",
    "\n",
    "for i in range(len(horo)):\n",
    "    horo.loc[i,'lon'] = json.loads(horo.loc[i,'geo_point_2d'])['lon']\n",
    "    horo.loc[i,'lat'] = json.loads(horo.loc[i,'geo_point_2d'])['lat']\n",
    "\n",
    "mean_latitude = horo.lat.mean()\n",
    "mean_longitude = horo.lon.mean()\n",
    "df = horo.drop(columns='geometry')\n",
    "\n",
    "layer = pdk.Layer(\n",
    "    \"ScatterplotLayer\",\n",
    "    df,\n",
    "    opacity=0.8,\n",
    "    stroked=True,\n",
    "    filled=True,\n",
    "    radius_scale=6,\n",
    "    radius_min_pixels=5,\n",
    "    radius_max_pixels=100,\n",
    "    line_width_min_pixels=0,\n",
    "    get_position=[\"lon\", \"lat\"],\n",
    "    pickable=True,\n",
    ")\n",
    "\n",
    "view_state = pdk.ViewState(longitude=mean_longitude, latitude=mean_latitude, zoom=15, bearing=0, pitch=0)\n",
    "\n",
    "r = pdk.Deck(layers=[layer],initial_view_state=view_state, map_provider=\"carto\",  map_style=\"light_no_labels\", tooltip={\"text\": \"{numhoro}\"})\n",
    "\n",
    "r.to_html('ScatterplotLayer.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This example highlights a fact: when the zoom level is high, displaying every point of our dataset is a good idea, as we can easily understand where each parking meter is located (which can be useful for finding one in a real-life context). \n",
    "\n",
    "However, when the zoom level is low (for example, when it's possible to see Paris as a whole), the map is saturated with information, as the raw representation of points is not optimized in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In fact, the problem with displaying all points at low zoom levels is not only that the map is saturated with points, but also that the map reader's needs are probably not the same.\n",
    "\n",
    "Indeed, when looking at the whole of Paris, the map reader's need is probably not to find the parking meters next to him, but more likely to understand how this equipment is distributed across the city (without understanding the precise location of each of them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To conclude this section, interactive maps do not solve the problem of cartographic representation of point data. In other words, it is always necessary to transform them at certain scales, in order to make the map more readable. \n",
    "\n",
    "These transformations are known as map generalization. CartAGen is a tool for carrying out these operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üõ† **Part 2 :** Exploring cartographic generalization techniques with CartAGen\n",
    "As we've seen, it's mostly scale that determines the choice of cartographic representation. Let's explore generalization techniques in terms of scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **2.1/** Point displacement techniques\n",
    "At large scales (i.e. small areas, high zoom levels...), we generally want to keep every point in our representation, in order to be as close as possible to reality. When points start to overlap, point displacement algorithms can be useful, as they make the map more legible while maintaining the number of points on the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.1.1/** Display the points to displace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Display points to displace\n",
    "admin = gp.read_file('data/puntos/arr_paris.geojson')\n",
    "admin.to_crs(crs=\"EPSG:3857\",inplace=True)\n",
    "horo.to_crs(crs=\"EPSG:3857\",inplace=True)\n",
    "horo_ok = gp.clip(horo, admin.loc[14:15])\n",
    "\n",
    "with progressbar.ProgressBar(max_value=2,widgets=widgets) as bar:\n",
    "    ax = admin.loc[14:15].plot(facecolor = 'None', edgecolor = \"grey\", linewidth = 0.5, figsize = (9,9))\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    scalebar = AnchoredSizeBar(ax.transData,\n",
    "                            1000,  \n",
    "                            '1000 m',  \n",
    "                            'lower left',  \n",
    "                            pad=0.5,\n",
    "                            color='black',\n",
    "                            frameon=True,\n",
    "                            size_vertical=1)\n",
    "    ax.add_artist(scalebar)\n",
    "\n",
    "    horo_ok.plot(ax=ax)\n",
    "    bar.update(1)\n",
    "    ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron)\n",
    "    bar.update(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Yet, there is no algorithm dedicated to point displacement in CartAGen. Nonetheless, it is possible to use the random_displacement algorithm by transforming our points into polygons before : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**2.1.2/** Converting points to polygons by creating buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Converting points to polygons by creating buffers\n",
    "horo_poly = horo_ok.copy()\n",
    "\n",
    "with progressbar.ProgressBar(max_value=len(horo_poly),widgets=widgets) as bar:\n",
    "    count = 0\n",
    "    for index, pt in horo_poly.iterrows():\n",
    "        horo_poly.loc[index,'geometry'] = horo_poly.loc[index,'geometry'].buffer(42)\n",
    "        count += 1\n",
    "        bar.update(count)\n",
    "if horo_poly.geometry.geom_type.unique()[0] == 'Polygon':\n",
    "    print(\"‚úÖ successful transformation\")\n",
    "else:\n",
    "    print(\"‚ùå transformation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.1.3/** Displacing points using the random_displacement algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "üí¨ Here, the ‚Äúmax trials‚Äù parameter is set to one, meaning that each entity that overlaps (or is too close) to another is moved once. \n",
    "\n",
    "If this parameter is set to two, the algorithm will perform the move twice (most likely in two different directions since it chooses randomly) and keep the situation with the fewest overlaps. \n",
    "\n",
    "A high value for this parameter will considerably lengthen calculation time (up to several minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hideOutput": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Displacing point buffers\n",
    "widgets1 = [\n",
    "    '', progressbar.Percentage(), ' ',  \n",
    "    progressbar.Bar(marker='üü©', left='', right='                        '), ' (', progressbar.ETA(), ') ' \n",
    "]\n",
    "def disp_pts(polygon_distance, max_trials, max_displacement):\n",
    "    global horo_poly\n",
    "    with progressbar.ProgressBar(max_value=4,widgets=widgets1) as bar:\n",
    "        bar.update(1)\n",
    "        horo_poly = cg.random_displacement(horo_poly, polygon_distance=polygon_distance, max_trials=max_trials, max_displacement=max_displacement)\n",
    "        bar.update(2)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize = (14,14))\n",
    "\n",
    "        axs[0].set_title('Before', pad=10, family='sans-serif')\n",
    "        axs[0].scatter(np.asarray(horo_ok.geometry.get_coordinates())[:,:1], np.asarray(horo_ok.geometry.get_coordinates())[:,-1])\n",
    "        bar.update(3)\n",
    "        axs[0].set_xlim(left=254968, right=259800)\n",
    "        axs[0].set_ylim(bottom=6248519, top=6255324)\n",
    "        axs[0].set_aspect('equal')\n",
    "        ctx.add_basemap(axs[0],source=ctx.providers.CartoDB.Positron)\n",
    "        fig.axes[0].get_xaxis().set_visible(False)\n",
    "        fig.axes[0].get_yaxis().set_visible(False)\n",
    "\n",
    "        axs[1].set_title('After', pad=10, family='sans-serif')\n",
    "        axs[1].scatter(np.asarray(horo_poly.geometry.centroid.get_coordinates())[:,:1], np.asarray(horo_poly.geometry.centroid.get_coordinates())[:,-1])\n",
    "        bar.update(4)\n",
    "        axs[1].set_xlim(left=254968, right=259800)\n",
    "        axs[1].set_ylim(bottom=6248519, top=6255324)\n",
    "        axs[1].set_aspect('equal')\n",
    "        ctx.add_basemap(axs[1],source=ctx.providers.CartoDB.Positron)\n",
    "        fig.axes[1].get_xaxis().set_visible(False)\n",
    "        fig.axes[1].get_yaxis().set_visible(False)\n",
    "   \n",
    "\n",
    "ipywidgets.interact(disp_pts, polygon_distance = ipywidgets.BoundedIntText(value=10, min=0, max=200, step=1,description='polygon distance',style={'description_width': 'initial'}),\n",
    "                              max_trials = ipywidgets.BoundedIntText(value=1, min=0, max=200, step=1,description='max trials'),\n",
    "                              max_displacement = ipywidgets.BoundedIntText(value=10, min=0, max=200, step=1,description='max displacement', style={'description_width': 'initial'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A low ‚Äúmax_trials‚Äù parameter reduces calculation time, but the displacement obtained is often unsatisfactory. A ‚Äúmax_trials‚Äù value of 25 is better in our case (but the calculation time is long)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2.1.3'/** Code details on random_displacement algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pm_polygons = horo_ok.copy() # copying the points to displace\n",
    "pm_polygons.geometry = pm_polygons.geometry.buffer(42) #changing point geometry to polygon geometry with 42 meters buffer \n",
    "\n",
    "pm_polygons = cg.random_displacement(pm_polygons, polygon_distance=20,\n",
    "                                                  max_trials=1, \n",
    "                                                  max_displacement=10)\n",
    "                                     #displacing polygons /!\\ can be long if max_trials is high\n",
    "\n",
    "pm_polygons.geometry = pm_polygons.geometry.centroid \n",
    "pm_polygons.plot(figsize=(9,9)) #after displacement\n",
    "horo_ok.plot(figsize=(9,9)) #before displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **2.2/** Point reduction techniques\n",
    "As the scale decreases, more and more points overlap, making it harder to perform displacement. At this point, having all the points on the map becomes less important: the map provides a global view of the spatial distribution of the data. Point reduction algorithms enable these transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.2.1/** Using reduce_kmeans algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Reduce_points_kmeans algorithm\n",
    "horo_ok = gp.clip(horo, admin.loc[13:16])\n",
    "\n",
    "def kmean(figure_size, shrink_ratio):\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (figure_size,figure_size))\n",
    "    with progressbar.ProgressBar(max_value=5,widgets=widgets) as bar:\n",
    "        horo_red = cg.reduce_kmeans(horo_ok,ratio=shrink_ratio,mode='simplification')\n",
    "        bar.update(1)\n",
    "        axs[0].set_title('Before', pad=10, family='sans-serif')\n",
    "        axs[0].scatter(x=np.asarray(horo_ok.geometry.get_coordinates())[:,:1], y= np.asarray(horo_ok.geometry.get_coordinates())[:,-1])\n",
    "        bar.update(2)\n",
    "        ctx.add_basemap(axs[0],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(3)\n",
    "        fig.axes[0].get_xaxis().set_visible(False)\n",
    "        fig.axes[0].get_yaxis().set_visible(False)\n",
    "        axs[0].set_aspect('equal')\n",
    "        \n",
    "        axs[1].set_title('After', pad=10, family='sans-serif')\n",
    "           \n",
    "        axs[1].scatter(np.asarray(horo_red.geometry.x), np.asarray(horo_red.geometry.y))\n",
    "        bar.update(4)\n",
    "        ctx.add_basemap(axs[1],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(5)\n",
    "        fig.axes[1].get_xaxis().set_visible(False)\n",
    "        fig.axes[1].get_yaxis().set_visible(False)\n",
    "        axs[1].set_aspect('equal')\n",
    "        \n",
    "ipywidgets.interact(kmean, figure_size = ipywidgets.IntSlider(value =16, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                           shrink_ratio = ipywidgets.FloatSlider(value =0.7, min = 0, max = 1,step = 0.01,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The kmeans point reduction algorithm tends to even out the spatial distribution of the point data set by deleting more points in areas of higher point density. This can be problematic, as the map representation may not reflect the actual spatial distribution. Here's another algorithm for reducing the number of points: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2.2.1'/** Code details on reduce_kmeans algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "horo_red = cg.reduce_kmeans(horo_ok,ratio=0.7,mode='simplification')\n",
    "\n",
    "horo_red.plot(figsize=(9,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.2.2/** Using reduce_quadtree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# reduce_points_quadtree algorithm (simplification mode)\n",
    "horo_ok = gp.clip(horo, admin.loc[13:16])\n",
    "\n",
    "def qtree_simp(figure_size, depth):\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (figure_size,figure_size))\n",
    "\n",
    "    # horo_red = cg.reduce_points_quadtree(horo_ok,5,mode='simplification')\n",
    "    # horo_red = [x[0] for x in horo_red[0]]\n",
    "    with progressbar.ProgressBar(max_value=5,widgets=widgets) as bar:\n",
    "        horo_red = cg.reduce_quadtree(horo_ok,depth=depth,mode='simplification')\n",
    "        bar.update(1)\n",
    "\n",
    "        axs[0].set_title('Before', pad=10, family='sans-serif')\n",
    "        axs[0].scatter(x=np.asarray(horo_ok.geometry.get_coordinates())[:,:1], y= np.asarray(horo_ok.geometry.get_coordinates())[:,-1])\n",
    "        bar.update(2)\n",
    "        ctx.add_basemap(axs[0],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(3)\n",
    "        fig.axes[0].get_xaxis().set_visible(False)\n",
    "        fig.axes[0].get_yaxis().set_visible(False)\n",
    "        axs[0].set_aspect('equal')\n",
    "\n",
    "        axs[1].set_title('After', pad=10, family='sans-serif')\n",
    "     \n",
    "        axs[1].scatter(np.asarray(horo_red.geometry.get_coordinates())[:,:1], y= np.asarray(horo_red.geometry.get_coordinates())[:,-1])\n",
    "            \n",
    "        bar.update(4)\n",
    "        ctx.add_basemap(axs[1],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(5)\n",
    "        fig.axes[1].get_xaxis().set_visible(False)\n",
    "        fig.axes[1].get_yaxis().set_visible(False)\n",
    "        axs[1].set_xlim(left=253668, right=261883)\n",
    "        axs[1].set_ylim(bottom=6248519, top=6258324)\n",
    "        axs[1].set_aspect('equal')\n",
    "\n",
    "ipywidgets.interact(qtree_simp, figure_size = ipywidgets.IntSlider(value =16, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                                depth = ipywidgets.IntSlider(value =5, min = 0, max = 8,step = 1,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The quadtree algorithm with reduction points appears to be faster in terms of processing time.\n",
    "It has the disadvantage of not allowing fine-tuning of the reduction force."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that these algorithms remove points based on their position, without taking attributes into account. In other words, if you wish to reduce points before configuring a symbology based on an attribute value, it's best to use the following techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2.2.2'/** Code details on reduce_quadtree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "reduced = cg.reduce_quadtree(horo_ok,depth=5,mode=\"simplification\") #Using the reduce_quadtree function on a gdf contianing our points\n",
    "\n",
    "reduced.plot(figsize=(9,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.2.3/** Adding a fake attribute to our datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's say we add an attribute containing the number of places in the parking area. Calling it \"nb_places\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Adding a fake value to parking meters points (let's say the number of places in the parking area)\n",
    "horo_value = horo.copy()\n",
    "with progressbar.ProgressBar(max_value=len(horo_value),widgets=widgets) as bar:\n",
    "    for i in range(len(horo_value)):\n",
    "        horo_value.loc[i,'nb_places'] = random.randint(1, 100) \n",
    "        bar.update(i)\n",
    "#create a field based on index for merging df later\n",
    "horo_value['index'] = horo_value.index\n",
    "print(\"Sample of our data containing the 'nb_places' attribute : \")\n",
    "horo_value[['nb_places','index','numhoro']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.2.4/** Using reduce_quadtree algorithm with an attribute value (\"selection mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The ‚Äúselection‚Äù mode selects the point with the highest value in the chosen column, weighted by the point's depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# reduce_quadtree algorithm (selection mode)\n",
    "horo_value_clp = gp.clip(horo_value, admin.loc[13:16])\n",
    "\n",
    "def qtree_attr(figure_size, depth, display_sizes):\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (figure_size,figure_size))\n",
    "\n",
    "    with progressbar.ProgressBar(max_value=5,widgets=widgets) as bar:\n",
    "        horo_red = cg.reduce_quadtree(horo_value_clp,depth=depth,mode=\"selection\",column='nb_places')\n",
    "        bar.update(1)\n",
    "\n",
    "        axs[0].set_title('Before', pad=10, family='sans-serif')\n",
    "        axs[0].scatter(x=np.asarray(horo_ok.geometry.get_coordinates())[:,:1], y= np.asarray(horo_ok.geometry.get_coordinates())[:,-1])\n",
    "        bar.update(2)\n",
    "        ctx.add_basemap(axs[0],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(3)\n",
    "        fig.axes[0].get_xaxis().set_visible(False)\n",
    "        fig.axes[0].get_yaxis().set_visible(False)\n",
    "        axs[0].set_aspect('equal')\n",
    "\n",
    "        axs[1].set_title('After', pad=10, family='sans-serif')\n",
    "        \n",
    "        if display_sizes == True:\n",
    "            axs[1].scatter(np.asarray(horo_red.geometry.get_coordinates())[:,:1], y= np.asarray(horo_red.geometry.get_coordinates())[:,-1], s= horo_red['nb_places'])\n",
    "        else:   \n",
    "            axs[1].scatter(np.asarray(horo_red.geometry.get_coordinates())[:,:1], y= np.asarray(horo_red.geometry.get_coordinates())[:,-1]) \n",
    "        bar.update(4)\n",
    "        ctx.add_basemap(axs[1],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(5)\n",
    "        fig.axes[1].get_xaxis().set_visible(False)\n",
    "        fig.axes[1].get_yaxis().set_visible(False)\n",
    "        axs[1].set_xlim(left=253668, right=261883)\n",
    "        axs[1].set_ylim(bottom=6248519, top=6258324)\n",
    "        axs[1].set_aspect('equal')\n",
    "\n",
    "ipywidgets.interact(qtree_attr, figure_size = ipywidgets.IntSlider(value =16, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                                depth = ipywidgets.IntSlider(value =5, min = 0, max = 8,step = 1,continuous_update=False),\n",
    "                                display_sizes = False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case, for each group of points in which the algorithm removes points, the point with the highest value is retained. However, the reduce_quadtree algorithm also tends to even out the spatial distribution. Note that this selection mode also exists in the reduce_kmeans algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2.2.4'/** Code details on reduce_quadtree algorithm with selection mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "reduced = cg.reduce_quadtree(horo_value_clp,depth=5,mode=\"selection\",column='nb_places')\n",
    "\n",
    "reduced.plot(figsize=(9,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.2.5/** Using reduce_labelgrid algorithm with selection mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Using the LabelGrid algorithm with selection mode \n",
    "horo_value_clp = gp.clip(horo_value, admin.loc[13:16])\n",
    "horo_value_clp.reset_index(inplace=True)\n",
    "extent = horo_value_clp.total_bounds\n",
    "\n",
    "def lb_selec(figure_size, shape, width, height, sizes, show_grid):\n",
    "    with progressbar.ProgressBar(max_value=5,widgets=widgets) as bar:\n",
    "        lg = cg.reduce_labelgrid(horo_value_clp, width = width, height = height, column=\"nb_places\", shape=shape, mode='selection', grid=True)\n",
    "        bar.update(1)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize = (figure_size,figure_size))\n",
    "\n",
    "        axs[0].set_title('Before', pad=10, family='sans-serif')\n",
    "        if sizes == True:\n",
    "            axs[0].scatter(x=np.asarray(horo_value_clp.geometry.get_coordinates())[:,:1], y= np.asarray(horo_value_clp.geometry.get_coordinates())[:,-1],s= horo_value_clp.nb_places)\n",
    "        else:\n",
    "            axs[0].scatter(x=np.asarray(horo_value_clp.geometry.get_coordinates())[:,:1], y= np.asarray(horo_value_clp.geometry.get_coordinates())[:,-1])\n",
    "        bar.update(2)\n",
    "        ctx.add_basemap(axs[0],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(3)\n",
    "        fig.axes[0].get_xaxis().set_visible(False)\n",
    "        fig.axes[0].get_yaxis().set_visible(False)\n",
    "        plt.xlim(extent[0]-350, extent[2]+350)\n",
    "        plt.ylim(extent[1]-350, extent[3]+350)\t\n",
    "        axs[0].set_aspect('equal')\n",
    "\n",
    "        axs[1].set_title('After', pad=10, family='sans-serif')\n",
    "        if show_grid == True:\n",
    "            for i in range(len(lg[1])):\n",
    "                poly = Path.make_compound_path(Path(np.asarray(lg[1].geometry[i].exterior.coords)[:, :2]),*[Path(np.asarray(ring.coords)[:, :2]) for ring in lg[1].geometry[i].interiors])\n",
    "                axs[1].add_patch(PathPatch(poly, facecolor= 'None', edgecolor='black',linewidth = 0.15, alpha= 0.7))\n",
    "\n",
    "        if sizes == True:\n",
    "            axs[1].scatter(x=np.asarray(lg[0].geometry.get_coordinates())[:,:1], y= np.asarray(lg[0].geometry.get_coordinates())[:,-1], s=lg[0].nb_places)\n",
    "        else:\n",
    "            axs[1].scatter(x=np.asarray(lg[0].geometry.get_coordinates())[:,:1], y= np.asarray(lg[0].geometry.get_coordinates())[:,-1])\n",
    "        bar.update(4)\n",
    "        ctx.add_basemap(axs[1],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(5)\n",
    "        fig.axes[1].get_xaxis().set_visible(False)\n",
    "        fig.axes[1].get_yaxis().set_visible(False)\n",
    "        plt.xlim(extent[0]-350, extent[2]+350)\n",
    "        plt.ylim(extent[1]-350, extent[3]+350)\n",
    "        axs[1].set_aspect('equal')\n",
    "\n",
    "ipywidgets.interact(lb_selec, figure_size = ipywidgets.IntSlider(value =16, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                              shape = ipywidgets.Dropdown(options=['square', 'diamond', 'hexagonal'], value='square', description='Cell shape:'),\n",
    "                              width = ipywidgets.IntSlider(value =250, min = 0, max = 1000,step = 1,continuous_update=False),\n",
    "                              height = ipywidgets.IntSlider(value =250, min = 0, max = 1000,step = 1,continuous_update=False),\n",
    "                              sizes = False,\n",
    "                              show_grid = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The Label Grid algorithm does essentially the same thing, but seems to preserve the spatial distribution of points to a greater extent, since the reduction force is the same everywhere (regardless of point density)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2.2.5'/** Code details on reduce_points_labelgrid algorithm with selection mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "reduced = cg.reduce_labelgrid(horo_value_clp, width = 500, height = 500,\n",
    "                                              shape=\"square\", \n",
    "                                              column=\"nb_places\", mode='selection')\n",
    "\n",
    "reduced.plot(figsize=(9,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **2.3/** Aggregation techniques\n",
    "At some point, it becomes pointless to display point data as dots on the map. Indeed, at smaller scales (the scale of Brittany in our first example, and the scale of Paris in the second), there is either too much information to display, or too much overlap between points. In cartography, there are several ways of solving this problem. Aggregation is one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Aggregation involves ‚Äúmerging‚Äù information from points into larger spatial entities (usually a polygon). A common type of aggregation is performed with administrative (or statistical) units. Aggregating into administrative units does not require CartAGen (only [Geopandas](https://geopandas.org/en/stable/) is used here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.3.1/** Perform aggregation in administrative/statistical units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Agregating points into adminstrative units in Paris\n",
    "def multipolygon_to_polygon(geom): # function that transform MultiPolygon geometry to Polygon\n",
    "    if isinstance(geom, MultiPolygon):\n",
    "        return geom.geoms[0]\n",
    "    return geom\n",
    "mun = admin.copy()\n",
    "mun.loc[:,'geometry'] = mun.loc[:,'geometry'].apply(multipolygon_to_polygon)\n",
    "neigh = gp.read_file('data/puntos/quartier_paris.geojson')\n",
    "neigh.to_crs(crs=\"EPSG:3857\",inplace=True)\n",
    "iris = gp.read_file('data/puntos/iris.geojson')\n",
    "iris.to_crs(crs=\"EPSG:3857\",inplace=True)\n",
    "iris.loc[:,'geometry'] = iris.loc[:,'geometry'].apply(multipolygon_to_polygon) \n",
    "\n",
    "horo_enr = gp.sjoin(horo_value, mun)\n",
    "horo_enr = horo_enr[[\"numhoro\",\"nb_places\",\"ID\",\"NOM\",\"geometry\"]]\n",
    "horo_enr = gp.sjoin(horo_enr, neigh)\n",
    "horo_enr = horo_enr[[\"numhoro\",\"nb_places\",\"ID\",\"NOM\",\"n_sq_qu\", \"l_qu\",\"geometry\"]]\n",
    "horo_enr = gp.sjoin(horo_enr, iris)\n",
    "horo_enr = horo_enr[[\"numhoro\",\"nb_places\",\"ID\",\"NOM\",\"n_sq_qu\", \"l_qu\",\"code_iris\",\"nom_iris\", \"geometry\"]]\n",
    "horo_enr['nb_pm'] = 1\n",
    "\n",
    "def agr_admin(figure_size, unit, value, show_units):\n",
    "    if unit == 'IRIS':\n",
    "        unit = 'code_iris'\n",
    "    elif unit == 'neighborhoods':\n",
    "        unit = 'n_sq_qu'\n",
    "    else:\n",
    "        unit = 'ID'\n",
    "\n",
    "    if value == 'sum of places':\n",
    "        value = 'nb_places'\n",
    "    else:\n",
    "        value = 'nb_pm'\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (figure_size,figure_size))\n",
    "    with progressbar.ProgressBar(max_value=6,widgets=widgets) as bar:\n",
    "        horo_agr = horo_enr.groupby([unit]).sum(['nb_pm'])\n",
    "        bar.update(1)\n",
    "        if unit == 'code_iris':\n",
    "            unit_to_disp = iris.merge(right=horo_agr, how='left', on = 'code_iris')\n",
    "        elif unit == 'n_sq_qu':\n",
    "            unit_to_disp = neigh.merge(right=horo_agr, how='left', on = 'n_sq_qu')\n",
    "        else:\n",
    "            unit_to_disp = mun.merge(right=horo_agr, how='left', on = 'ID')\n",
    "        bar.update(2)\n",
    "        axs[0].set_title('Before', pad=10, family='sans-serif')\n",
    "        axs[0].scatter(x=np.asarray(horo.geometry.get_coordinates())[:,:1], y= np.asarray(horo.geometry.get_coordinates())[:,-1])\n",
    "        bar.update(3)\n",
    "        ctx.add_basemap(axs[0],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(4)\n",
    "        fig.axes[0].get_xaxis().set_visible(False)\n",
    "        fig.axes[0].get_yaxis().set_visible(False)\n",
    "        axs[0].set_aspect('equal')\n",
    "        axs[0].set_xlim(left=249654, right=272000)\n",
    "        axs[0].set_ylim(bottom=6243332, top=6258584)\n",
    "\n",
    "        axs[1].set_title('After', pad=10, family='sans-serif')\n",
    "        if value == 'nb_places':\n",
    "            axs[1].scatter(np.asarray(unit_to_disp.geometry.centroid.get_coordinates())[:,:1], y= np.asarray(unit_to_disp.geometry.centroid.get_coordinates())[:,-1], s= unit_to_disp[value]*0.2)\n",
    "        else:\n",
    "            axs[1].scatter(np.asarray(unit_to_disp.geometry.centroid.get_coordinates())[:,:1], y= np.asarray(unit_to_disp.geometry.centroid.get_coordinates())[:,-1], s= unit_to_disp[value])\n",
    "        if show_units == True:\n",
    "            for i in range(len(unit_to_disp)):\n",
    "                poly = Path.make_compound_path(Path(np.asarray(unit_to_disp.geometry[i].exterior.coords)[:, :2]),*[Path(np.asarray(ring.coords)[:, :2]) for ring in unit_to_disp.geometry[i].interiors])\n",
    "                axs[1].add_patch(PathPatch(poly, facecolor= 'None', edgecolor='black',linewidth = 0.15))\n",
    "        bar.update(5)\n",
    "        ctx.add_basemap(axs[1],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(6)\n",
    "        fig.axes[1].get_xaxis().set_visible(False)\n",
    "        fig.axes[1].get_yaxis().set_visible(False)\n",
    "        axs[1].set_aspect('equal')\n",
    "        axs[1].set_xlim(left=249654, right=272000)\n",
    "        axs[1].set_ylim(bottom=6243332, top=6258584)\n",
    "\n",
    "ipywidgets.interact(agr_admin, figure_size = ipywidgets.IntSlider(value =16, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                               unit = ipywidgets.Dropdown(options=['IRIS', 'neighborhoods', 'municipalities'], value='neighborhoods', description='Agregation units:',style = {'description_width': 'initial'}),\n",
    "                               value = ipywidgets.Dropdown(options=['sum of places', 'count of parking meters'], value='count of parking meters', description='Values represented:',style = {'description_width': 'initial'}),\n",
    "                               show_units = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this way, you can represent aggregated data in polygonal units in the form of circles. You can also represent these units directly and define their color according to the information they contain (instead of indicating it by the size of the circle). However, this requires the calculation of ratio indicators, as it is not recommended to display stock values with colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.3.2/** Display aggregated datas in choroplete map style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Creating ratio indicators to display agregated data in choroplete map style\n",
    "mun.to_crs(crs=\"EPSG:2154\",inplace=True)\n",
    "mun['area'] = mun['geometry'].area/1000000 #square kilometers\n",
    "\n",
    "neigh.to_crs(crs=\"EPSG:2154\",inplace=True)\n",
    "neigh['area'] = neigh['geometry'].area/1000000\n",
    "\n",
    "iris.to_crs(crs=\"EPSG:2154\",inplace=True)\n",
    "iris['area'] = iris['geometry'].area/1000000\n",
    "\n",
    "def agr_admin_choro(figure_size, unit, value, colors):\n",
    "    fig = plt.figure(1, (figure_size, figure_size))\n",
    "\n",
    "    if value == 'sum of places':\n",
    "        value = 'nb_places'\n",
    "    else:\n",
    "        value = 'nb_pm'\n",
    "\n",
    "    if unit == 'IRIS':\n",
    "        unit = 'code_iris'\n",
    "    elif unit == 'neighborhoods':\n",
    "        unit = 'n_sq_qu'\n",
    "    else:\n",
    "        unit = 'ID'\n",
    "\n",
    "    \n",
    "    horo_agr = horo_enr.groupby([unit]).sum(['nb_pm'])\n",
    "        \n",
    "    if unit == 'code_iris':\n",
    "        unit_to_disp = iris.merge(right=horo_agr, how='left', on = 'code_iris')\n",
    "    elif unit == 'n_sq_qu':\n",
    "        unit_to_disp = neigh.merge(right=horo_agr, how='left', on = 'n_sq_qu')\n",
    "    else:\n",
    "        unit_to_disp = mun.merge(right=horo_agr, how='left', on = 'ID')\n",
    "    with progressbar.ProgressBar(max_value=len(unit_to_disp)*2,widgets=widgets) as bar:    \n",
    "        for i in range(len(unit_to_disp)):\n",
    "            unit_to_disp.loc[i,'density'] = unit_to_disp.loc[i,value]/unit_to_disp.loc[i,'area']\n",
    "            bar.update(i)\n",
    "        unit_to_disp = unit_to_disp.dropna()\n",
    "        unit_to_disp = unit_to_disp.reset_index(drop = True)\n",
    "        unit_to_disp.loc[:,'geometry'] = unit_to_disp.loc[:,'geometry'].apply(multipolygon_to_polygon) \n",
    "        unit_to_disp.to_crs(crs=\"EPSG:3857\", inplace=True)\n",
    "\n",
    "        sub1 = fig.add_subplot(121)\n",
    "        sub1.set_title('Before', pad=10, family='sans-serif')\n",
    "        sub1.scatter(x=np.asarray(horo.geometry.get_coordinates())[:,:1], y= np.asarray(horo.geometry.get_coordinates())[:,-1])\n",
    "        ctx.add_basemap(sub1,source=ctx.providers.CartoDB.Positron)\n",
    "        sub1.axes.get_xaxis().set_visible(False)\n",
    "        sub1.axes.get_yaxis().set_visible(False)\n",
    "        sub1.set_aspect('equal')\n",
    "        sub1.set_xlim(left=249654, right=272000)\n",
    "        sub1.set_ylim(bottom=6243332, top=6258584)\n",
    "\n",
    "        sub2 = fig.add_subplot(122)\n",
    "        sub2.set_title('After', pad=10, family='sans-serif')\n",
    "        cmap = plt.get_cmap(colors)\n",
    "        norm = mcolors.Normalize(vmin=unit_to_disp['density'].min(), vmax=unit_to_disp['density'].max())\n",
    "\n",
    "        for j in range(len(unit_to_disp)):\n",
    "            color_value = unit_to_disp.loc[j, 'density']/unit_to_disp.loc[:, 'density'].max()\n",
    "            color = cmap(color_value)\n",
    "\n",
    "            poly = Path.make_compound_path(Path(np.asarray(unit_to_disp.geometry[j].exterior.coords)[:, :2]),*[Path(np.asarray(ring.coords)[:, :2]) for ring in unit_to_disp.geometry[j].interiors])\n",
    "            sub2.add_patch(PathPatch(poly, facecolor= color, edgecolor='black',linewidth = 0.15, alpha = 0.7))\n",
    "            bar.update(i+j)\n",
    "        mappable = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "        mappable.set_array(unit_to_disp['density'])\n",
    "        cbar = fig.colorbar(mappable, ax = sub2, fraction=0.03, pad=-0.025, orientation='vertical')\n",
    "        cbar.set_label(f'{value} per km¬≤')  \n",
    "\n",
    "        sub2.axes.get_xaxis().set_visible(False)\n",
    "        sub2.axes.get_yaxis().set_visible(False)\n",
    "        sub2.set_aspect('equal') \n",
    "        sub2.set_xlim(left=249654, right=272000)\n",
    "        sub2.set_ylim(bottom=6243332, top=6258584)\n",
    "        ctx.add_basemap(sub2,source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "ipywidgets.interact(agr_admin_choro, figure_size = ipywidgets.IntSlider(value =16, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                               unit = ipywidgets.Dropdown(options=['IRIS', 'neighborhoods', 'municipalities'], value='neighborhoods', description='Agregation units:',style = {'description_width': 'initial'}),\n",
    "                               value = ipywidgets.Dropdown(options=['sum of places', 'count of parking meters'], value='count of parking meters', description='Values represented:', style = {'description_width': 'initial'}),\n",
    "                               colors = ipywidgets.Dropdown(options=['Reds', 'YlOrRd','viridis'], value='Reds', description='Color palette:', style = {'description_width': 'initial'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can identify two main problems with this technique:\n",
    "- There are not always administrative/statistical units available for the area being mapped.\n",
    "- There are sometimes large differences in size between units, making the spatial distribution of data more difficult to read (which can be partially solved by creating ratio indicators)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For those reasons, it can be interesting to aggregate our points into regular geographical entities, such as the cells of a grid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.3.3/** Using reduce_point_labelgrid (agregation mode) to perform aggregation in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Using the Label Grid algorithm to aggregate datas \n",
    "horo_value.to_crs(crs='EPSG:3857',inplace=True)\n",
    "extent = horo_value.total_bounds\n",
    "\n",
    "def agr_grid(figure_size, width, height, shape, value,show_grid):\n",
    "    with progressbar.ProgressBar(max_value=5,widgets=widgets) as bar:\n",
    "        lg = cg.reduce_labelgrid(horo_value, width = width, height = height, column=\"nb_places\", shape=shape, mode='aggregation',grid=True)\n",
    "        bar.update(1)\n",
    "        fig, axs = plt.subplots(1, 2, figsize = (figure_size,figure_size))\n",
    "\n",
    "        axs[0].set_title('Before', pad=10, family='sans-serif')\n",
    "        axs[0].scatter(x=np.asarray(horo_value.geometry.get_coordinates())[:,:1], y= np.asarray(horo_value.geometry.get_coordinates())[:,-1])\n",
    "        bar.update(2)\n",
    "        ctx.add_basemap(axs[0],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(3)\n",
    "        fig.axes[0].get_xaxis().set_visible(False)\n",
    "        fig.axes[0].get_yaxis().set_visible(False)\n",
    "        plt.xlim(extent[0]-350, extent[2]+350)\n",
    "        plt.ylim(extent[1]-350, extent[3]+350)\t\n",
    "        axs[0].set_aspect('equal')\n",
    "\n",
    "        axs[1].set_title('After', pad=10, family='sans-serif')\n",
    "        if show_grid == True:\n",
    "            for i in range(len(lg[1])):\n",
    "                poly = Path.make_compound_path(Path(np.asarray(lg[1].geometry[i].exterior.coords)[:, :2]),*[Path(np.asarray(ring.coords)[:, :2]) for ring in lg[1].geometry[i].interiors])\n",
    "                axs[1].add_patch(PathPatch(poly, facecolor= 'None', edgecolor='black',linewidth = 0.15, alpha= 0.7))\n",
    "            \n",
    "        if value == 'count of parking meters':\n",
    "            axs[1].scatter(x=np.asarray(lg[0].geometry.get_coordinates())[:,:1], y= np.asarray(lg[0].geometry.get_coordinates())[:,-1], s=lg[0]['count']*2.5)\n",
    "        else:\n",
    "            axs[1].scatter(x=np.asarray(lg[0].geometry.get_coordinates())[:,:1], y= np.asarray(lg[0].geometry.get_coordinates())[:,-1], s=lg[0]['sum']*0.15)\n",
    "        bar.update(4)\n",
    "        ctx.add_basemap(axs[1],source=ctx.providers.CartoDB.Positron)\n",
    "        bar.update(5)\n",
    "        fig.axes[1].get_xaxis().set_visible(False)\n",
    "        fig.axes[1].get_yaxis().set_visible(False)\n",
    "        plt.xlim(extent[0]-350, extent[2]+350)\n",
    "        plt.ylim(extent[1]-350, extent[3]+350)\n",
    "        axs[1].set_aspect('equal')\n",
    "\n",
    "ipywidgets.interact(agr_grid, figure_size = ipywidgets.IntSlider(value =16, min = 1, max = 20,step = 1,continuous_update=False),\n",
    "                              shape = ipywidgets.Dropdown(options=['square', 'diamond', 'hexagonal'], value='square', description='Cell shape:'),\n",
    "                              width = ipywidgets.IntSlider(value =500, min = 0, max = 1000,step = 1,continuous_update=False),\n",
    "                              height = ipywidgets.IntSlider(value =500, min = 0, max = 1000,step = 1,continuous_update=False),\n",
    "                              value = ipywidgets.Dropdown(options=['sum of places', 'count of parking meters'], value='count of parking meters', description='Values represented:', style = {'description_width': 'initial'}),\n",
    "                              show_grid =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As with administrative units, you can display data in the form of colored grid cells. Each cell has the same size, so data can be displayed without having to calculate a ratio indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2.3.3'/** Code details on reduce_labelgrid (aggregation mode) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lg = cg.reduce_labelgrid(horo_value, width = 500, height = 500,\n",
    "                                     column=\"nb_places\", \n",
    "                                     shape=\"square\", mode='aggregation')\n",
    "\n",
    "lg.plot(figsize=(9,9), markersize = \"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.3.4/** Display the aggregation grid from reduce_labelgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Display the grid from Label Grid agregation \n",
    "horo_value.to_crs(crs='EPSG:3857',inplace=True)\n",
    "extent = horo_value.total_bounds\n",
    "\n",
    "def agr_grid_choro(figure_size, width, height, shape, value, colors):\n",
    "    lg = cg.reduce_labelgrid(horo_value, width = width, height = height, shape=shape, mode=\"aggregation\", column = \"nb_places\", grid=True)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize = (figure_size,figure_size))\n",
    "\n",
    "    axs[0].set_title('Before', pad=10, family='sans-serif')\n",
    "    axs[0].scatter(x=np.asarray(horo_value.geometry.get_coordinates())[:,:1], y= np.asarray(horo_value.geometry.get_coordinates())[:,-1],s=2)\n",
    "    ctx.add_basemap(axs[0],source=ctx.providers.CartoDB.Positron)\n",
    "    fig.axes[0].get_xaxis().set_visible(False)\n",
    "    fig.axes[0].get_yaxis().set_visible(False)\n",
    "    plt.xlim(extent[0]-350, extent[2]+350)\n",
    "    plt.ylim(extent[1]-350, extent[3]+350)\n",
    "    axs[0].set_aspect('equal')\n",
    "    if value == 'count of parking meters':\n",
    "        value = 'count'\n",
    "    else:\n",
    "        value = 'sum'\n",
    "\n",
    "    axs[1].set_title('After', pad=10, family='sans-serif')\n",
    "    cmap = plt.get_cmap(colors)\n",
    "    norm = mcolors.Normalize(vmin=lg[1][value].min(), vmax=lg[1][value].max())\n",
    "    with progressbar.ProgressBar(max_value=len(lg[1]),widgets=widgets) as bar:\n",
    "        for i in range(len(lg[1])):\n",
    "            color_value = lg[1].loc[i, value]/lg[1].loc[:, value].max()\n",
    "            color = cmap(color_value)\n",
    "            \n",
    "            poly = Path.make_compound_path(Path(np.asarray(lg[1].geometry[i].exterior.coords)[:, :2]),*[Path(np.asarray(ring.coords)[:, :2]) for ring in lg[1].geometry[i].interiors])\n",
    "            if color != (0,0,0,0):\n",
    "                axs[1].add_patch(PathPatch(poly, facecolor= color, edgecolor='black',linewidth = 0.15, alpha= 0.7))\n",
    "            bar.update(i)\n",
    "    mappable = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    mappable.set_array(lg[1][value])\n",
    "    cbar = fig.colorbar(mappable, ax = axs[1], fraction=0.03, pad=-0.025, orientation='vertical')\n",
    "    cbar.set_label(f'{value}')\n",
    "\n",
    "    ctx.add_basemap(axs[1],source=ctx.providers.CartoDB.Positron)\n",
    "    fig.axes[1].get_xaxis().set_visible(False)\n",
    "    fig.axes[1].get_yaxis().set_visible(False)\n",
    "    plt.xlim(extent[0]-350, extent[2]+350)\n",
    "    plt.ylim(extent[1]-350, extent[3]+350)\n",
    "    axs[1].set_aspect('equal')\n",
    "\n",
    "ipywidgets.interact(agr_grid_choro, figure_size = ipywidgets.IntSlider(value =16, min = 1, max = 20,step = 1,continuous_update=False),\n",
    "                              shape = ipywidgets.Dropdown(options=['square', 'diamond', 'hexagonal'], value='square', description='Cell shape:'),\n",
    "                              width = ipywidgets.IntSlider(value =500, min = 0, max = 1000,step = 1,continuous_update=False),\n",
    "                              height = ipywidgets.IntSlider(value =500, min = 0, max = 1000,step = 1,continuous_update=False),\n",
    "                              colors = ipywidgets.Dropdown(options=['Reds', 'YlOrRd','viridis'], value='Reds', description='Color palette:', style = {'description_width': 'initial'}),\n",
    "                              value = ipywidgets.Dropdown(options=['sum of places', 'count of parking meters'], value='count of parking meters', description='Values represented:', style = {'description_width': 'initial'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2.3.4'/** Code details of reduce_labelgrid to display aggregation grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lg = cg.reduce_labelgrid(horo_value, width = 500, height = 500, shape=\"square\", mode=\"aggregation\", \n",
    "                                     column = \"nb_places\",\n",
    "                                     grid=True)\n",
    "    \n",
    "lg[1].plot(figsize=(9,9),column=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aggregations are good techniques for a high level of generalization, which is useful when the aim of the map is to give an overall idea of the spatial distribution of a set of point data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, it is often difficult to determine the level of aggregation that best suits the map: units/cells that are too large mask local variations in data distribution, while units/cells that are too small give too much detail on the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To overcome this problem and avoid having to choose an aggregation level, the heat map technique can be used.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **2.4/** The heat map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The heat map (or spatial smoothing) is a technique that involves estimating the density of point data at any point in the mapped area. Let's take a look at Kernel Density Estimation (KDE), the most common technique for constructing a heat map:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.4.1/** Using the heatmap algorithm from CartAGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "admin.to_crs(crs='EPSG:2154', inplace=True)\n",
    "horo_value.to_crs(crs='EPSG:2154',inplace=True)\n",
    "\n",
    "def heatm(cell_size, radius, activate_weighting, colors, figure_size, method, clip):    \n",
    "    with progressbar.ProgressBar(max_value=3,widgets=widgets) as bar:\n",
    "        if activate_weighting == True and clip==True:\n",
    "            hm = cg.heatmap(horo_value, cell_size=cell_size, radius=radius, column=\"nb_places\",clip=admin,method=method)\n",
    "        elif activate_weighting == True and clip==False:\n",
    "            hm = cg.heatmap(horo_value, cell_size=cell_size, radius=radius, column=\"nb_places\", method=method)\n",
    "        elif activate_weighting == False and clip==True:\n",
    "            hm = cg.heatmap(horo_value, cell_size=cell_size, radius=radius, clip = admin, method=method)\n",
    "        else:\n",
    "            hm = cg.heatmap(horo_value, cell_size=cell_size, radius=radius, method=method)\n",
    "        bar.update(1)\n",
    "        ax = hm.plot(column=\"density\",cmap=colors,alpha=0.85,figsize=(figure_size,figure_size))\n",
    "        bar.update(2)\n",
    "        ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron,crs='EPSG:2154')\n",
    "        bar.update(3)\n",
    "\n",
    "ipywidgets.interact(heatm, figure_size = ipywidgets.IntSlider(value =12, min = 1, max = 20,step = 1,continuous_update=False),\n",
    "                           cell_size = ipywidgets.IntSlider(value =250, min = 0, max = 1000, step = 1,continuous_update=False),\n",
    "                           radius = ipywidgets.IntSlider(value =1000, min = 0, max = 3000, step = 1,continuous_update=False),\n",
    "                           activate_weighting = False,\n",
    "                           clip = False,\n",
    "                           method = ipywidgets.Dropdown(options=['quartic'], value='quartic', description='Smoothing method:', style = {'description_width': 'initial'}),\n",
    "                           colors = ipywidgets.Dropdown(options=['Reds', 'YlOrRd','viridis'], value='Reds', description='Color palette:', style = {'description_width': 'initial'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**2.4.1'/** Code details on the heatmap algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#make sure the input layer are in the same projected crs\n",
    "horo_value.to_crs(crs='EPSG:2154',inplace=True)\n",
    "admin.to_crs(crs='EPSG:2154', inplace=True)\n",
    "\n",
    "hm = cg.heatmap(horo_value, cell_size= 250,radius= 1000, method=\"quartic\", column=\"nb_places\",clip=admin)\n",
    "hm.plot(column=\"density\") #the output is a gdf that you can display using the .plot() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **2.5/** What about Brittany ? Where is the highest density of creperies ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we return to our first problem, we understand that we need strong generalization processes to be able to read the spatial distribution of points, given that there is a lot of overlap. Let's try aggregation into administrative units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.5.1/** Aggregating points into communes of Brittany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def multipolygon_to_polygon(geom): # function that transform MultiPolygon geometry to Polygon\n",
    "    if isinstance(geom, MultiPolygon):\n",
    "        return geom.geoms[0]\n",
    "    return geom\n",
    "\n",
    "com_brittany = gp.read_file('data/puntos/com_britt.geojson')\n",
    "com_brittany.loc[:,'geometry'] = com_brittany.loc[:,'geometry'].apply(multipolygon_to_polygon) \n",
    "\n",
    "crepes_enr = gp.sjoin(crepes, com_brittany)\n",
    "crepes_enr = crepes_enr[[\"NOM_M\",\"ID\",\"POPULATION\",\"full_id\",\"geometry\"]]\n",
    "\n",
    "crepes_agr = crepes_enr.groupby([\"ID\"]).count()\n",
    "crepes_com = com_brittany.merge(right=crepes_agr, how='left', on = 'ID')\n",
    "crepes_com = crepes_com[[\"NOM_M_x\",\"POPULATION_y\",\"geometry_x\"]]\n",
    "crepes_com.set_geometry(\"geometry_x\", inplace=True, crs=\"EPSG:2154\")\n",
    "\n",
    "def plt_aggr(figure_size,symbology):\n",
    "    with progressbar.ProgressBar(max_value=len(crepes_com),widgets=widgets) as bar:\n",
    "        if symbology == \"circle\":\n",
    "            for i in range(len(crepes_com)):\n",
    "                if crepes_com.loc[i,'POPULATION_y'] != crepes_com.loc[i,'POPULATION_y']:\n",
    "                    crepes_com.loc[i,'POPULATION_y'] = 0\n",
    "                crepes_com.loc[i,'nb_rest_ok'] = crepes_com.loc[i,'POPULATION_y']*15 \n",
    "                bar.update(i)\n",
    "            crepes_cir = crepes_com.copy() \n",
    "            crepes_cir.geometry = crepes_cir.geometry.centroid \n",
    "            ax=com_brittany.plot(figsize=(figure_size,figure_size),facecolor='None',edgecolor=\"lightgrey\",linewidth=0.5)\n",
    "            crepes_cir.plot(ax=ax,markersize =\"nb_rest_ok\", legend=True,color='b', alpha=0.6)\n",
    "            for size in [1, 3, 25]:  \n",
    "                plt.scatter([], [], s=size*15, label=str(size), color='b', alpha=0.6)\n",
    "\n",
    "            plt.legend(scatterpoints=1, frameon=True, labelspacing=1, title='nb of restaurants')\n",
    "\n",
    "            cities = crepes_cir[(crepes_com['nb_rest_ok'] > 225)]\n",
    "            for idx, row in cities.iterrows():\n",
    "                ax.text(row.geometry_x.x, row.geometry_x.y, row['NOM_M_x'], fontsize=8, ha='center')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "        else:\n",
    "            crepes_com['density'] = (crepes_com['nb_rest_ok']/15)/(crepes_com.geometry.area/1000000)\n",
    "            for i in range(len(crepes_com)):\n",
    "                if crepes_com.loc[i,'density'] != crepes_com.loc[i,'density']:\n",
    "                    crepes_com.loc[i,'density'] = 0\n",
    "                sleep(0.001)\n",
    "                bar.update(i)\n",
    "            ax= crepes_com.plot(column =\"density\", cmap='YlOrRd',scheme='NaturalBreaks', legend_kwds={\"title\":\"Restaurant per km2 \\n (natural breaks)\"},legend=True,figsize=(figure_size,figure_size))\n",
    "            com_brittany.plot(ax=ax,facecolor='None',edgecolor=\"lightgrey\",linewidth=0.5)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "ipywidgets.interact(plt_aggr, figure_size = ipywidgets.IntSlider(value =12, min = 1, max = 20,step = 1,continuous_update=False),\n",
    "                              symbology = ipywidgets.Dropdown(options=['circle','choroplete'], value='circle', description='Symbology:', style = {'description_width': 'initial'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The proportional circles on the map clearly show which cities have the most creperies. Quimper, Rennes and Saint-Malo are the top three.\n",
    "The choropleth map gives a different view of this distribution, since the number of restaurants is weighted by the surface area of the commune. In this case, it is more difficult to read the spatial distribution with this method, as very small towns have high densities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's create an heatmap with those data, to get rid of the impact of the administrative boundaries in our cartographic representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**2.5.1/** Use the heatmap technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "com_brittany.to_crs(crs='EPSG:2154', inplace=True)\n",
    "crepes.to_crs(crs='EPSG:2154',inplace=True)\n",
    "\n",
    "def heatm_brit(cell_size, radius, colors, figure_size, method, clip):    \n",
    "    with progressbar.ProgressBar(max_value=4,widgets=widgets) as bar:\n",
    "        bar.update(1)\n",
    "        if clip==True:\n",
    "            hm = cg.heatmap(crepes, cell_size=cell_size, radius=radius,clip=com_brittany,method=method)\n",
    "        else:\n",
    "            hm = cg.heatmap(crepes, cell_size=cell_size, radius=radius, method=method)\n",
    "   \n",
    "        bar.update(2)\n",
    "        ax = hm.plot(column=\"density\",cmap=colors,alpha=0.85,figsize=(figure_size,figure_size))\n",
    "        bar.update(3)\n",
    "        ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron,crs='EPSG:2154')\n",
    "        bar.update(4)\n",
    "\n",
    "ipywidgets.interact(heatm_brit, figure_size = ipywidgets.IntSlider(value =12, min = 1, max = 20,step = 1,continuous_update=False),\n",
    "                           cell_size = ipywidgets.IntSlider(value =2500, min = 0, max = 10000, step = 1,continuous_update=False),\n",
    "                           radius = ipywidgets.IntSlider(value =15000, min = 0, max = 30000, step = 1,continuous_update=False),\n",
    "                           clip = True,\n",
    "                           method = ipywidgets.Dropdown(options=['quartic'], value='quartic', description='Smoothing method:', style = {'description_width': 'initial'}),\n",
    "                           colors = ipywidgets.Dropdown(options=['Reds', 'YlOrRd','viridis'], value='Reds', description='Color palette:', style = {'description_width': 'initial'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this case, the heat map can be used to highlight areas with a high density of restaurants, independently of administrative units. For example, although Rennes and Quimper have a similar number of creperies, the Rennes and surrounding area has a much higher density than Quimper and surrounding area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, the problem with the heat map technique is that the quality of the representation also depends on the number of input points. In this case, there are large empty spaces due to the lack of points (especially when the radius parameter is small), which is not ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üìç**Part 3 :** Creating cluster map with CartAGen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Cluster maps are a new way to represent point datasets, especially large ones. They consist of an interactive map in which points are merged into clusters. As you zoom out of the map, the clusters become fewer and more points are grouped together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More and more tools allow you to create these maps. This is the case for some webmapping tools like Leaflet or Mapbox. Here is an example of what a map of parking meter clusters in Paris could look like with Leaflet\n",
    "\n",
    "![Alt text](https://raw.githubusercontent.com/gowestmen/images/refs/heads/main/cluster_map.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This interactive map is interesting because it allows you to navigate between different zoom levels without encountering the problem of overlapping points. However, the sizes of the circles are not proportional, and you can't really configure how the clusters are calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using CartAGen and other libraries can be a solution to fully control the process of creating a cluster map. Let's try it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **3.1/** Point aggregation into clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first step to create our cluster map is to regroup our points into clusters. To perform that, we will use the [Scikit learn](https://scikit-learn.org/stable/api/sklearn.cluster.html#module-sklearn.cluster) Python library, which contains a lot of clustering algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**3.1.1/** Creating clusters using DBSCAN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "horo.to_crs(crs='EPSG:2154',inplace=True) #make sure the point dataset is in projected coordinate \n",
    "coords = np.vstack((horo.geometry.x, horo.geometry.y)).T #retrieve coordinates and put them in an array object\n",
    "\n",
    "def clstr(eps, min_samples, figure_size):\n",
    "    dbscan = cluster.DBSCAN(eps=eps, min_samples=min_samples) #instanciate dbscan class, specifiying parameters\n",
    "    # i.e eps = max distance for points to be consider in the same cluster\n",
    "    #  min_samples = minimum number of close points to form a cluster\n",
    "    clusters = dbscan.fit_predict(coords) #compute the clusters\n",
    "    horo['cluster'] = clusters #add the id of the cluster of each point as a new column\n",
    "\n",
    "    list_col_clus = []\n",
    "    with progressbar.ProgressBar(max_value=len(horo.cluster.unique()),widgets=widgets) as bar:\n",
    "        for i in range(len(horo.cluster.unique())):\n",
    "            list_col_clus.append((np.random.uniform(0, 1),np.random.uniform(0, 1),np.random.uniform(0, 1)))\n",
    "            bar.update(i)\n",
    "        col_clus = matcol.LinearSegmentedColormap.from_list('col_clus',list_col_clus)\n",
    "\n",
    "        if len(horo.cluster.unique()) > 1:\n",
    "            horo.plot(column=\"cluster\", cmap=col_clus, figsize=(figure_size,figure_size)) #plot result\n",
    "        else:\n",
    "            horo.plot(color=\"grey\", figsize=(figure_size,figure_size))\n",
    "\n",
    "ipywidgets.interact(clstr, figure_size = ipywidgets.IntSlider(value =12, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                             eps = ipywidgets.IntSlider(value =500, min = 1, max = 2000,step = 1,continuous_update=False),\n",
    "                             min_samples = ipywidgets.IntSlider(value =5, min = 1, max = 200,step = 1,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "DBSCAN has the advantage of not assigning each point to a cluster. Points that are too isolated are thus considered as non-clustered. However, it is difficult to find clusters of equal sizes in our case. Let's try another clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**3.1.2/** Creating clusters using HDBSCAN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "horo_copy = horo.copy()\n",
    "horo_copy.to_crs(crs='EPSG:2154',inplace=True) #make sure the point dataset is in projected coordinate \n",
    "coords = np.vstack((horo.geometry.x, horo.geometry.y)).T #retrieve coordinates and put them in an array object\n",
    "\n",
    "def clstr_2(min_cluster_size, figure_size):\n",
    "    hdb = cluster.HDBSCAN(min_cluster_size=min_cluster_size) #instanciate dbscan class, specifiying parameters\n",
    "    # i.e eps = max distance for points to be consider in the same cluster\n",
    "    #  min_samples = minimum number of close points to form a cluster\n",
    "    clusters = hdb.fit_predict(coords) #compute the clusters\n",
    "    horo_copy['cluster'] = clusters #add the id of the cluster of each point as a new column\n",
    "\n",
    "    list_col_clus = []\n",
    "    with progressbar.ProgressBar(max_value=len(horo_copy.cluster.unique()),widgets=widgets) as bar:\n",
    "        for i in range(len(horo_copy.cluster.unique())):\n",
    "            list_col_clus.append((np.random.uniform(0, 1),np.random.uniform(0, 1),np.random.uniform(0, 1)))\n",
    "            bar.update(i)\n",
    "        col_clus = matcol.LinearSegmentedColormap.from_list('col_clus',list_col_clus)\n",
    "\n",
    "        if len(horo_copy.cluster.unique()) > 1:\n",
    "            horo_copy.plot(column=\"cluster\", cmap=col_clus, figsize=(figure_size,figure_size)) #plot result\n",
    "        else:\n",
    "            horo_copy.plot(color=\"grey\", figsize=(figure_size,figure_size))\n",
    "\n",
    "ipywidgets.interact(clstr_2, figure_size = ipywidgets.IntSlider(value =12, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                           min_cluster_size = ipywidgets.IntSlider(value =5, min = 2, max = 200,step = 1,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The HDBSCAN algorithm is designed to detect clusters of different densities, something that the DBSCAN algorithm struggles to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, these two algorithms do not give satisfactory results because the point data sets here do not present large differences in density (the location of the parking meters is regular in space)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's use another clustering algorithm, based on distance and not density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**3.1.3/** Creating clusters using K-means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "horo_ok = gp.read_file(\"horo_ok.geojson\")\n",
    "coords = np.vstack((horo_ok.geometry.x, horo_ok.geometry.y)).T #retrieve coordinates and put them in an array object\n",
    "\n",
    "def clstr_3(n_clusters, figure_size):\n",
    "    with progressbar.ProgressBar(max_value=n_clusters,widgets=widgets) as bar:\n",
    "        kmeans = cluster.KMeans(n_clusters=n_clusters, random_state=42) #instanciate dbscan class, specifiying parameters\n",
    "        # i.e n_clusters = the number of clusters to find in the dataset \n",
    "        # random_state = used to have always the same choices regarding the initial centro√Øds\n",
    "        clusters = kmeans.fit_predict(coords) #compute the clusters\n",
    "        horo_ok['cluster'] = clusters #add the id of the cluster of each point as a new column\n",
    "\n",
    "        list_col_clus = []\n",
    "        for i in range(len(horo_ok.cluster.unique())):\n",
    "            list_col_clus.append((np.random.uniform(0, 1),np.random.uniform(0, 1),np.random.uniform(0, 1)))\n",
    "            bar.update(i)\n",
    "        col_clus = matcol.LinearSegmentedColormap.from_list('col_clus',list_col_clus)\n",
    "\n",
    "        if len(horo_ok.cluster.unique()) > 1:\n",
    "            horo_ok.plot(column=\"cluster\", cmap=col_clus, figsize=(figure_size,figure_size)) #plot result\n",
    "        else:\n",
    "            horo_ok.plot(color=\"grey\", figsize=(figure_size,figure_size))\n",
    "    \n",
    "ipywidgets.interact(clstr_3, figure_size = ipywidgets.IntSlider(value =12, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                           n_clusters = ipywidgets.IntSlider(value =5, min = 1, max = 20,step = 1,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The K-means algorithm is easier to configure, because you can choose the number of clusters you want. This algorithm groups all points into clusters, even those that seem isolated. Here we have removed the parking meters that are really far from the rest of the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **3.2/** Compute the hulls of the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now that we have calculated our clusters, we need to determine the spatial hull of each cluster, which will be used in the final map representation, and for calculating the number of points per cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**3.2.1/** Separate the GeoDataFrame containing the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#separating dataset in x clusters\n",
    "list_clusters = []\n",
    "with progressbar.ProgressBar(max_value=len(horo_ok.cluster.unique()),widgets=widgets) as bar:\n",
    "    for i in range(len(horo_ok.cluster.unique())):\n",
    "        list_clusters.append(horo_ok[(horo_ok.cluster == i)])\n",
    "        bar.update(i)\n",
    "\n",
    "if len(list_clusters) > 1:\n",
    "    print(\"successful separation\")\n",
    "    print(\"nb of clusters : \"+str(len(list_clusters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We now have a list of x GeoDataFrame (depending on the number of clusters). Let's use CartAGen to compute the hull of each of these clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**3.2.2/** Using CartAGen to compute the hulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#compute clusters covering\n",
    "unclusters = gp.read_file(\"unclusterd.geojson\")\n",
    "\n",
    "def hull(length, figure_size):\n",
    "    global hulls\n",
    "    list_hulls = []\n",
    "    with progressbar.ProgressBar(max_value=len(list_clusters),widgets=widgets) as bar:\n",
    "        c = 0\n",
    "        for i in list_clusters:\n",
    "            c += 1\n",
    "            list_hulls.append(cg.hull_delaunay(list(i.geometry),length=length))\n",
    "            bar.update(c)\n",
    "        hulls = gp.GeoDataFrame(geometry=gp.GeoSeries(list_hulls))  \n",
    "        ax = hulls.plot(cmap='Reds',figsize=(figure_size, figure_size))\n",
    "        unclusters.plot(ax=ax)\n",
    "\n",
    "ipywidgets.interact(hull, figure_size = ipywidgets.IntSlider(value =10, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                           length = ipywidgets.IntSlider(value =2000, min = 1, max = 3000,step = 1,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**3.2.2'/** Details on CartAGen's hull_delaunay algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "list_hulls_demo = []\n",
    "for i in list_clusters:\n",
    "    list_hulls_demo.append(cg.hull_delaunay(list(i.geometry),length=2000))\n",
    "            \n",
    "hulls_demo = gp.GeoDataFrame(geometry=gp.GeoSeries(list_hulls_demo))  \n",
    "        \n",
    "ax = hulls_demo.plot(cmap='Reds')\n",
    "unclusters.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**3.2.3/** Calculate the number of points per hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hulls = hulls.set_crs(crs='EPSG:2154') #specify the crs of the hulls\n",
    "horo['nb'] = 1 #creates a column for count of points\n",
    "\n",
    "#creating id for each hull\n",
    "with progressbar.ProgressBar(max_value=len(hulls),widgets=widgets) as bar:\n",
    "    for i in range(len(hulls)):\n",
    "        hulls.loc[i,\"id_hull_1\"] = i\n",
    "        bar.update(i)\n",
    "horo_id_hull = gp.sjoin(horo, hulls) #transfer the id of hull in each overlaping points\n",
    "horo_hull_agr = horo_id_hull.groupby(['id_hull_1']).sum(['nb']) #get the sum of points for each hull id\n",
    "hulls_count = hulls.merge(right=horo_hull_agr, how='left', on = 'id_hull_1') #merge this sum into the hull GeoDataFrame\n",
    "hulls_count = hulls_count[['geometry','id_hull_1','nb']]\n",
    "hulls_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**3.2.4/** Display the cluster map for low level of zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Creates the map for the first zoom level\n",
    "\n",
    "ax = hulls_count.plot(facecolor = 'None', edgecolor = \"grey\")\n",
    "ax.scatter(x=np.asarray(hulls_count.geometry.centroid.get_coordinates())[:,:1], y= np.asarray(hulls_count.centroid.get_coordinates())[:,-1], s=hulls_count['nb']*5)\n",
    "for i, label in enumerate(hulls_count['nb']):\n",
    "    plt.annotate(label, (np.asarray(hulls_count.geometry.centroid.get_coordinates())[:,:1][i], np.asarray(hulls_count.centroid.get_coordinates())[:,-1][i]), \n",
    "                         ha='center',fontsize=20, color=\"white\")\n",
    "\n",
    "ctx.add_basemap(ax,source=ctx.providers.CartoDB.Positron, crs='EPSG:2154')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With this process, we obtain a personalized map of the clusters of the parking meters of Paris. The next steps consist in calculating new clusters within each hull to obtain a less generalized layer, which will be displayed in an interactive map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **3.3/** Build an interactive map combining diffrent clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**3.3.1/** Compute new clusters within each hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "list_horo_lvl2 = []\n",
    "list_coords_lvl2 = []\n",
    "for i in range(len(horo_id_hull.id_hull_1.unique())):\n",
    "    list_horo_lvl2.append(horo_id_hull[(horo_id_hull.id_hull_1 == i)])\n",
    "\n",
    "list_coords_lvl2 = []\n",
    "for i in range(len(list_horo_lvl2)):\n",
    "    list_coords_lvl2.append(np.vstack((list_horo_lvl2[i].geometry.x, list_horo_lvl2[i].geometry.y)).T)\n",
    " \n",
    "\n",
    "def clstr_4(figure_size,n_clusters):\n",
    "    kmeans = cluster.KMeans(n_clusters=n_clusters, random_state=42) #instanciate dbscan class, specifiying parameters\n",
    "    # i.e n_clusters = the number of clusters to find in the dataset \n",
    "    # random_state = used to have always the same choices regarding the initial centro√Øds\n",
    "    clusters = kmeans.fit_predict(list_coords_lvl2[0]) #compute the clusters\n",
    "    list_horo_lvl2[0].loc[:,'cluster'] = clusters #add the id of the cluster of each point as a new column\n",
    "\n",
    "    list_col_clus_lvl2 = []\n",
    "    with progressbar.ProgressBar(max_value=len(list_horo_lvl2[0].cluster.unique()),widgets=widgets) as bar:\n",
    "        for i in range(len(list_horo_lvl2[0].cluster.unique())):\n",
    "            list_col_clus_lvl2.append((np.random.uniform(0, 1),np.random.uniform(0, 1),np.random.uniform(0, 1)))\n",
    "            bar.update(i)\n",
    "        col_clus = matcol.LinearSegmentedColormap.from_list('col_clus',list_col_clus_lvl2)\n",
    "\n",
    "        if len(list_horo_lvl2[0].cluster.unique()) > 1:\n",
    "            ax = list_horo_lvl2[0].plot(column=\"cluster\", cmap=col_clus, figsize=(figure_size,figure_size)) #plot result\n",
    "        else:\n",
    "            ax =list_horo_lvl2[0].plot(color=\"grey\", figsize=(figure_size,figure_size))\n",
    "\n",
    "ipywidgets.interact(clstr_4, figure_size = ipywidgets.IntSlider(value =8, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                           n_clusters = ipywidgets.IntSlider(value =5, min = 1, max = 20,step = 1,continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can imagine choosing a different clustering algorithm for each hull, in order to be sure to make the best choice given the spatial distribution of the points. This process can be long, that is why we decide to apply the same K-means algorithm for each hull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def hulls_2(length, n_clusters, figure_size):\n",
    "    global hulls_count_2\n",
    "    list_clusters_2 = []\n",
    "    kmeans = cluster.KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "    for i in range(len(list_coords_lvl2)):\n",
    "        clusters = kmeans.fit_predict(list_coords_lvl2[i])\n",
    "        list_horo_lvl2[i].loc[:,'cluster'] = clusters\n",
    "        for j in range(n_clusters):\n",
    "            list_clusters_2.append(list_horo_lvl2[i][(list_horo_lvl2[i].cluster == j)])\n",
    "\n",
    "    list_hulls_2 = []\n",
    "    with progressbar.ProgressBar(max_value=len(list_clusters_2),widgets=widgets) as bar:\n",
    "        for i in list_clusters_2:\n",
    "            list_hulls_2.append(cg.hull_delaunay(list(i.geometry),length=length))\n",
    "            bar.update(i)\n",
    "    hulls_2 = gp.GeoDataFrame(geometry=gp.GeoSeries(list_hulls_2))\n",
    "\n",
    "    hulls_2 = hulls_2.set_crs(crs='EPSG:2154') #specify the crs of the hulls_2\n",
    "\n",
    "    #creating id for each hull\n",
    "    for i in range(len(hulls_2)):\n",
    "        hulls_2.loc[i,\"id_hull_2\"] = i\n",
    "\n",
    "    horo_id_hull_2 = gp.sjoin(horo, hulls_2) #transfer the id of hull in each overlaping points\n",
    "    horo_hull_agr_2 = horo_id_hull_2.groupby(['id_hull_2']).sum(['nb']) #get the sum of points for each hull id\n",
    "    hulls_count_2 = hulls_2.merge(right=horo_hull_agr_2, how='left', on = 'id_hull_2') #merge this sum into the hull GeoDataFrame\n",
    "    hulls_count_2 = hulls_count_2[['geometry','id_hull_2','nb']]\n",
    "\n",
    "    hulls_2.plot(cmap='Reds', figsize=(figure_size,figure_size))\n",
    "\n",
    "ipywidgets.interact(hulls_2, figure_size = ipywidgets.IntSlider(value =8, min = 1, max = 16,step = 1,continuous_update=False),\n",
    "                           n_clusters = ipywidgets.IntSlider(value =4, min = 1, max = 20,step = 1,continuous_update=False),\n",
    "                           length = ipywidgets.IntSlider(value =2000, min = 1, max = 3000,step = 1,continuous_update=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**3.3.2/** Combining the hulls in an interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "horo_clean = horo.loc[:,['numhoro','adresse','geometry']]\n",
    "horo_clean.to_crs(crs='EPSG:4326', inplace=True)\n",
    "hulls_count.to_crs(crs='EPSG:4326', inplace=True)\n",
    "hulls_count_2.to_crs(crs='EPSG:4326', inplace=True)\n",
    "unclusters.to_crs(crs='EPSG:4326', inplace=True)\n",
    "\n",
    "\n",
    "m = ipyleaflet.Map(center=(48.8566, 2.3522), zoom=15,min_zoom =12, max_zoom = 18, basemap=ipyleaflet.basemaps.CartoDB.Positron)\n",
    "\n",
    "def flip(x, y):\n",
    "    return y, x\n",
    "\n",
    "def create_markers_from_gdf(gdf):\n",
    "    global markers\n",
    "    markers = []\n",
    "    for _, row in gdf.iterrows():\n",
    "        lon = gdf.loc[_,'geometry'].x\n",
    "        lat = gdf.loc[_,'geometry'].y\n",
    "\n",
    "        circle_marker = ipyleaflet.CircleMarker(location=(lat, lon), radius=5, fill_opacity=0.7)\n",
    "        markers.append(circle_marker)\n",
    "\n",
    "def create_poly_from_gdf(gdf):\n",
    "    global polys\n",
    "    polys = []\n",
    "\n",
    "    for _, row in gdf.iterrows():\n",
    "        row['geometry'] = transform(flip, row['geometry'])\n",
    "        coords = list(row['geometry'].exterior.coords) \n",
    "        polygon = ipyleaflet.Polygon(locations=coords, color=\"blue\", fill_color=\"blue\", fill_opacity = 0, weight=2)\n",
    "        polys.append(polygon)\n",
    "\n",
    "def create_circle_from_gdf(gdf):\n",
    "    global circle_2\n",
    "    circle_2 = []\n",
    "\n",
    "    for _, row in gdf.iterrows():\n",
    "        lon = gdf.loc[_,'geometry'].centroid.x\n",
    "        lat = gdf.loc[_,'geometry'].centroid.y\n",
    "\n",
    "        circle_marker = ipyleaflet.CircleMarker(location=(lat, lon), radius=int(row['nb']*0.1), fill_opacity=0.7, weight=2)\n",
    "        circle_2.append(circle_marker)\n",
    "\n",
    "create_poly_from_gdf(hulls_count)\n",
    "layer_group_2 = ipyleaflet.LayerGroup(layers=polys)\n",
    "create_circle_from_gdf(hulls_count)\n",
    "layer_group_2_circle = ipyleaflet.LayerGroup(layers=circle_2)\n",
    "\n",
    "\n",
    "create_poly_from_gdf(hulls_count_2)\n",
    "layer_group_3 = ipyleaflet.LayerGroup(layers=polys)\n",
    "create_circle_from_gdf(hulls_count_2)\n",
    "layer_group_3_circle = ipyleaflet.LayerGroup(layers=circle_2)\n",
    "\n",
    "create_markers_from_gdf(unclusters)\n",
    "uncluster_pts = ipyleaflet.LayerGroup(layers=markers)\n",
    "\n",
    "create_markers_from_gdf(horo_clean)\n",
    "layer_group = ipyleaflet.LayerGroup(layers=markers)\n",
    "m.add_layer(layer_group)\n",
    "\n",
    "def on_zoom_change(event):\n",
    "    if m.zoom < 13:\n",
    "        if len(m.layers[1].layers) != len(hulls_count):\n",
    "            for i in range(len(hulls_count_2)+3):\n",
    "                m.remove_layer(m.layers[1])\n",
    "            m.add_layer(layer_group_2_circle)\n",
    "            m.add_layer(uncluster_pts)\n",
    "            for i,row in hulls_count.iterrows():\n",
    "                m.add(ipyleaflet.Popup(location=[row['geometry'].centroid.y,row['geometry'].centroid.x],child=ipywidgets.HTML(value = str(row['nb'])), auto_close = False, auto_pan=False))\n",
    "            m.add_layer(layer_group_2)\n",
    "            \n",
    "                      \n",
    "\n",
    "    elif 12 < m.zoom < 15:\n",
    "        if len(m.layers[1].layers) != len(hulls_count_2):\n",
    "            if len(m.layers) > 2:\n",
    "                for i in range(len(hulls_count)+3):\n",
    "                    m.remove_layer(m.layers[1])\n",
    "            else:\n",
    "                m.remove_layer(m.layers[1])\n",
    "            m.add_layer(layer_group_3_circle)\n",
    "            m.add_layer(uncluster_pts)\n",
    "            for i,row in hulls_count_2.iterrows():\n",
    "                m.add(ipyleaflet.Popup(location=[row['geometry'].centroid.y,row['geometry'].centroid.x],child=ipywidgets.HTML(value = str(row['nb'])), auto_close = False, auto_pan=False))\n",
    "            m.add_layer(layer_group_3)\n",
    "            \n",
    "    else:\n",
    "        if len(m.layers) > 2:\n",
    "            for i in range(len(hulls_count_2)+3):\n",
    "                m.remove_layer(m.layers[1])\n",
    "       \n",
    "            m.add_layer(layer_group)\n",
    "    \n",
    "m.observe(on_zoom_change, names='zoom')\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To conclude on this example, we can say that a cluster map can be useful to represent all the parking meter data since there are many points to represent. Keep in mind that this resulting interactive map could be improved, both in terms of interactivity (being able to get information about each parking meter by clicking on it...) and symbology (improving the design of the popups indicating the number of points...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Moreover, when it comes to representing a point dataset in an interactive map, clustering is not the only technique! In fact, all the generalization methods presented in this Notebook could be combined in a webmap. One can imagine starting with a heatmap at a low zoom level, then an aggregate representation, a reduction/displacement of points and finally a display of raw points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thank you for your attention !"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rise": {
   "autolaunch": true,
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
